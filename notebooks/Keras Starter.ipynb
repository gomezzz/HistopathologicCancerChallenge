{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append other folders to path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "#Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Make this notebook full width\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#Imports\n",
    "import numpy as np\n",
    "import keras,os,gc,datetime\n",
    "import logging\n",
    "from Utils.zscore_images import *\n",
    "from IO.load_training_data import *\n",
    "from IO.load_test_data import *\n",
    "from Models.NASNet_mobile import *\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "logging.basicConfig(level=0) #show all logging output\n",
    "\n",
    "np.random.seed(42) #set numpy seed to easy reproducibility\n",
    "\n",
    "training_portion = 0.8 # use 80% of samples for training, rest validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the training data from /Datasets/ , we'll shuffle later\n",
    "# If this throws an error, you probably haven't create a hdf5 dataset yet\n",
    "# In that case run /Scripts/runDataAugmentation\n",
    "X,y = load_training_data_h5(shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NASNet_mobile() # Sets up a NASNetMobile. First time will load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup keras training\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(0.0008),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "model.fit(x=X, y=y, batch_size=50, epochs=1, verbose=0, callbacks=[TQDMNotebookCallback()], \n",
    "    validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free RAM\n",
    "X = None\n",
    "y = None\n",
    "gc.collect();\n",
    "\n",
    "# Loads the training data from /Datasets/ , we'll shuffle later\n",
    "# If this throws an error, you probably haven't create a hdf5 dataset yet\n",
    "# In that case run /Scripts/createTestHDF5\n",
    "X = load_test_data_h5() \n",
    "\n",
    "logging.info(\"Loading file names\")\n",
    "test_files = glob(os.path.join(\"../Datasets/test/\",'*.tif')) #find the test file names\n",
    "submission = pd.DataFrame() #create a dataframe to hold results\n",
    "test_df = pd.DataFrame({'path': test_files}) #add the filenames to the dataframe\n",
    "#add the ids to the dataframe\n",
    "if os.name == 'nt': #deal with windows backslashes\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('\\\\')[1].split(\".\")[0])\n",
    "else:\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "\n",
    "logging.info(\"Predicting labels\")\n",
    "predictions = model.predict(X,verbose = 1) #predict the labels for the test data\n",
    "\n",
    "logging.info(\"Storing submission\")\n",
    "test_df['label'] = predictions #store them in the dataframe\n",
    "submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n",
    "submission.head() #display first lines\n",
    "submission.to_csv(\"../Out/submission_\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))+\".csv\", index = False, header = True) #create the submission file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
