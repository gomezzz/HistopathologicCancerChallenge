{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "This code is inspired by https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3',context='paper', fscale=1, spines=True, gridlines='-',ticks=True, grid=True, figsize=(6, 6)) #somehow calling this once is not sufficient...\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') \n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os,cv2,keras\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from Models.NASNet_mobile import *\n",
    "from Analysis.analyze_test_results import *\n",
    "from Utils.CLR.clr_callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "np.random.seed(42)\n",
    "model_path = \"../Out/nasnet.h5\"\n",
    "batch_size = 150\n",
    "\n",
    "#Utility functions\n",
    "def chunker(seq, size): #this is useful for iterating\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "def get_id_from_file_path(file_path): #returns id for a given path\n",
    "    return file_path.split(os.path.sep)[-1].replace('.tif', '')\n",
    "def auc(y_true, y_pred): # AUC metric for keras, might be a little slow though (it approximates it during training too)\n",
    "    auc = tf.metrics.auc(y_true, y_pred,summation_method='careful_interpolation',num_thresholds=100)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the filenames etc. for streaming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../Datasets/train_labels.csv\")\n",
    "df_test = pd.read_csv(\"../Data/compare_with_github/test_labels_from_github.csv\") #load extracted test labels\n",
    "id_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n",
    "id_test_map = {k:v for k,v in zip(df_test.id.values, df_test.label.values)}\n",
    "labeled_files = glob('../Datasets/train/*.tif')\n",
    "test_files = glob('../Datasets/test/*.tif')\n",
    "train = labeled_files\n",
    "val = test_files #we just validate on the extracted test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the streaming data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd67e144f327114229b410e0af43b71f45ce0d72"
   },
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "def get_seq():\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.6, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            iaa.Fliplr(0.5), # horizontally flip \n",
    "            iaa.Flipud(0.5), # vertically flip \n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)}, # scale images\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate images\n",
    "                rotate=(-90, 90), # rotate \n",
    "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "            )),\n",
    "            iaa.SomeOf((0, 8),\n",
    "                [\n",
    "                    sometimes(iaa.Superpixels(p_replace=(0, 0.5), n_segments=(20, 100))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 0.75)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
    "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 0.5)), # emboss images\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.25), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.05), per_channel=0.2),\n",
    "                    ]),\n",
    "                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "#Data generator that continuously create new augmented images\n",
    "def data_gen(list_files, id_label_map, batch_size, augment=False):\n",
    "    seq = get_seq()\n",
    "    while True:\n",
    "        shuffle(list_files)\n",
    "        for batch in chunker(list_files, batch_size):\n",
    "            X = [cv2.imread(x) for x in batch]\n",
    "            Y = [id_label_map[get_id_from_file_path(x)] for x in batch]\n",
    "            if augment:\n",
    "                X = seq.augment_images(X)\n",
    "            X = [keras.applications.nasnet.preprocess_input(x) for x in X]\n",
    "            yield np.array(X), np.array(Y)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NASNet_mobile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0872139964e7b1e7a25b327941b68fc3f90daa46"
   },
   "outputs": [],
   "source": [
    "#Setup keras training\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(0.00075),\n",
    "              metrics=['accuracy',auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db0b06f165a011723aef4266bf1be50b977268c5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.load_weights(model_path) #if you want to load the last model\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(model_path, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,step_size=1000, mode='triangular2') \n",
    "\n",
    "history = model.fit_generator(\n",
    "    data_gen(train, id_label_map, batch_size, augment=True),\n",
    "    validation_data=data_gen(val, id_test_map, batch_size),\n",
    "    epochs=8, verbose=0,\n",
    "    callbacks=[checkpoint,clr,TQDMNotebookCallback(leave_inner = True, leave_outer = True)],\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    validation_steps=len(val) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the test predictions and store submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "787cec513417ebb2c703d48b0ba97e1c4344c8d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path) # load the best model from training\n",
    "\n",
    "#compute test predictions\n",
    "preds = []\n",
    "ids = []\n",
    "TTA = True #should we use TTA\n",
    "for batch in tqdm_notebook(chunker(test_files, batch_size),total=len(test_files)/batch_size):\n",
    "    X = [keras.applications.nasnet.preprocess_input(cv2.imread(x)) for x in batch]\n",
    "    ids_batch = [get_id_from_file_path(x) for x in batch]\n",
    "    X = np.array(X)\n",
    "    if TTA: # 4x TTA\n",
    "        preds_batch = ((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "    else: # No TTA\n",
    "        preds_batch = model.predict(X).ravel().tolist()\n",
    "    preds += preds_batch\n",
    "    ids += ids_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.style(theme='grade3',context='paper', fscale=1, spines=True, gridlines='-',ticks=True, grid=True, figsize=(6, 6)) #set plotting style again... (some bug)\n",
    "analyze_test_results(ids,preds,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b531bfe1d28a7bae83b74d9f857ae0f7029fdd2"
   },
   "outputs": [],
   "source": [
    "#store the submission\n",
    "df = pd.DataFrame({'id':ids, 'label':preds})\n",
    "df.to_csv(\"../Out/submission_\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))+\".csv\", index = False, header = True) #create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutdown the pc\n",
    "import subprocess\n",
    "cmdCommand = \"shutdown -s\"\n",
    "process = subprocess.Popen(cmdCommand.split(), stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights manually if desired\n",
    "model.save_weights(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
